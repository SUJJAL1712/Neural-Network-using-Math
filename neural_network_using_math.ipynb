{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **INITIALIZATION**"
      ],
      "metadata": {
        "id": "BmGGGbumoJOg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azXkf-a0T44_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# configure path of the kaggle.json file\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "ZJcuFlSLLZq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c digit-recognizer"
      ],
      "metadata": {
        "id": "6dxxW_pKLc6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting the compressed dataset\n",
        "from zipfile import ZipFile\n",
        "dataset = '/content/digit-recognizer.zip'\n",
        "with ZipFile(dataset, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(\"dataset is extracted\")"
      ],
      "metadata": {
        "id": "WWszl3yKLiyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **DIVIDING THE DATASET**"
      ],
      "metadata": {
        "id": "1Mr8OGrMoX7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/train.csv\")\n",
        "print(data.head())\n",
        "data = np.array(data)"
      ],
      "metadata": {
        "id": "ad-RLDC4OMGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m, n = data.shape\n",
        "print(m,n) # 42000 data sets, 784 pixels + 1 label"
      ],
      "metadata": {
        "id": "xVkWCpXW9mz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.shuffle(data)\n",
        "\n",
        "data_dev = data[0:1000].T # dividing the test set, transposing so each column is a example\n",
        "y_dev = data_dev[0]\n",
        "x_dev = data_dev[1:n]\n",
        "x_dev = x_dev / 255\n",
        "\n",
        "data_train = data[1000:m].T # the training data set\n",
        "y_train = data_train[0]\n",
        "x_train = data_train[1:n]\n",
        "x_train = x_train / 255"
      ],
      "metadata": {
        "id": "U0MwVjyMOSKh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **DEFINING THE NEURAL NETWORK FUNCTIONS**"
      ],
      "metadata": {
        "id": "a59NTC8yoeGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_params():\n",
        "  w1 = np.random.rand(10,784) - 0.5\n",
        "  b1 = np.random.rand(10,1) - 0.5\n",
        "  w2 = np.random.rand(10,10) - 0.5\n",
        "  b2 = np.random.rand(10,1) - 0.5\n",
        "  return w1, b1, w2, b2\n",
        "\n",
        "def ReLU(z):\n",
        "  return np.maximum(z,0)\n",
        "\n",
        "def softmax(z):\n",
        "  A = np.exp(z) / sum(np.exp(z))\n",
        "  return A\n",
        "\n",
        "def forward_prop(w1,b1,w2,b2,x):\n",
        "  z1 = w1.dot(x) + b1\n",
        "  a1 = ReLU(z1)\n",
        "  z2 = w2.dot(a1) + b2\n",
        "  a2 = softmax(z2)\n",
        "  return z1, a1, z2, a2\n",
        "\n",
        "def deriv_ReLU(z):\n",
        "  return z>0\n",
        "\n",
        "def one_hot(y):\n",
        "    one_hot_y = np.zeros((y.size, y.max() + 1))\n",
        "    one_hot_y[np.arange(y.size), y] = 1\n",
        "    one_hot_y = one_hot_y.T\n",
        "    return one_hot_y\n",
        "\n",
        "def back_prop(z1,a1,z2,a2,w1,w2,x,y):\n",
        "  one_hot_y = one_hot(y)\n",
        "  dz2 = a2 - one_hot_y\n",
        "  dw2 = 1/m * dz2.dot(a1.T)\n",
        "  db2 = 1/m * np.sum(dz2)\n",
        "  dz1 = w2.T.dot(dz2) * deriv_ReLU(z1)\n",
        "  dw1 = 1/m * dz1.dot(x.T)\n",
        "  db1 = 1/m * np.sum(dz1)\n",
        "  return dw1, db1, dw2, db2\n",
        "\n",
        "def update_params(w1, b1, w2, b2, dw1, db1, dw2, db2, alpha):\n",
        "  w1 = w1 - alpha*dw1\n",
        "  b1 = b1 - alpha*db1\n",
        "  w2 = w2 - alpha*dw2\n",
        "  b2 = b2 - alpha*db2\n",
        "  return w1, b1, w2, b2"
      ],
      "metadata": {
        "id": "_kbrYCRuAb16"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TRAINING THE DATA**"
      ],
      "metadata": {
        "id": "V0BtJpqkoqJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(a2):\n",
        "  return np.argmax(a2, 0)\n",
        "\n",
        "def get_accuracy(predictions, y):\n",
        "  print(predictions, y)\n",
        "  return np.sum(predictions == y)/y.size\n",
        "\n",
        "def gradient_descent(x, y, iterations, alpha):\n",
        "  w1, b1, w2, b2 = init_params()\n",
        "  for i in range(iterations):\n",
        "    z1, a1, z2, a2 = forward_prop(w1, b1, w2, b2, x)\n",
        "    dw1, db1, dw2, db2 = back_prop(z1,a1,z2,a2,w1,w2,x,y)\n",
        "    w1, b1, w2, b2 = update_params(w1, b1, w2, b2, dw1, db1, dw2, db2, alpha)\n",
        "    if i%50 == 0:\n",
        "      print(\"iteration: \", i)\n",
        "      predictions = get_predictions(a2)\n",
        "      print(\"accuracy: \", (get_accuracy(predictions, y)))\n",
        "  return w1, b1, w2, b2"
      ],
      "metadata": {
        "id": "nJx-3lmSo9YG"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1, b1, w2, b2 = gradient_descent(x_train, y_train, 500, 0.10)"
      ],
      "metadata": {
        "id": "0OkGOJFRq-hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TESTING ON THE TRAINING DATASET**"
      ],
      "metadata": {
        "id": "ckbQSfd2ouPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(x,w1,b1,w2,b2):\n",
        "  _, _, _, a2 = forward_prop(w1,b1,w2,b2,x)\n",
        "  predictions = get_predictions(a2)\n",
        "  return predictions\n",
        "\n",
        "def test_predictions(index,w1,b1,w2,b2):\n",
        "  currect_image = x_train[:, index, None]\n",
        "  predictions = make_predictions(x_train[:, index, None], w1,b1,w2,b2)\n",
        "  label = y_train[index]\n",
        "  print(\"predictions: \", predictions)\n",
        "  print(\"label: \", label)\n",
        "  current_image = currect_image.reshape((28,28))*255\n",
        "  plt.gray()\n",
        "  plt.imshow(current_image, interpolation = 'nearest')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "2pVcWuATrLtI"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions(0,w1,b1,w2,b2)\n",
        "test_predictions(1,w1,b1,w2,b2)\n",
        "test_predictions(2,w1,b1,w2,b2)"
      ],
      "metadata": {
        "id": "HJrsYNjLncWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CHECKING THE ACCURACY ON THE TEST SET**"
      ],
      "metadata": {
        "id": "YFrhyllmo4dW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dev_predictions = make_predictions(x_dev, w1,b1,w2,b2)\n",
        "get_accuracy(dev_predictions, y_dev)"
      ],
      "metadata": {
        "id": "Ww-kfODHni3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **THE ACCURACY IS AROUND 85%**"
      ],
      "metadata": {
        "id": "Le-unVzUo_0j"
      }
    }
  ]
}